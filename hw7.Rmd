---
title: "Practicing Mapping"
author: "Abby Bergman"
date: "11/14/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#load packages
library(tidyverse)
library(ggmap)
library(RColorBrewer)
library(gridExtra)
library(fiftystater)
library(rscorecard)
library(knitr)
library(dplyr)
library(dbplyr)
library(RSQLite)
library(sf)
library(viridis)
```


#USA data
data("fifty_states")
as_tibble(fifty_states) 

#make simple feature
st_as_sf(fifty_states, coords = c("long", "lat"))%>% 
  
  # convert fifty_states to an sf data frame
  (sf_fifty <- st_as_sf(fifty_states, coords = c("long", "lat")) %>% 
     # convert sets of points to polygons
     group_by(id, piece) %>% 
     summarize(do_union = FALSE) %>%
     st_cast("POLYGON") %>%
     # convert polygons to multipolygons for states with discontinuous regions
     group_by(id) %>%
     summarize())

ggplot(data = sf_fifty) +
  geom_sf()




```{r}

#import school data
schools_by_state <- read_csv("/Users/AbigailBergman/Desktop/Grad School/Fall Quarter 2018/Computing/Homework/hw7/schools_by_state.csv")

population <- read_csv("/Users/AbigailBergman/Desktop/Grad School/Fall Quarter 2018/Computing/Homework/hw7/population.csv")


# convert fifty_states to an sf data frame
(sf_fifty <- st_as_sf(fifty_states, coords = c("long", "lat")) %>% 
   # convert sets of points to polygons
   group_by(id, piece) %>% 
   summarize(do_union = FALSE) %>%
   st_cast("POLYGON") %>%
   # convert polygons to multipolygons for states with discontinuous regions
   group_by(id) %>%
   summarize())

#need to do left join
combined1 <-left_join(schools_by_state %>% mutate(id = tolower(id)), sf_fifty, by = "id") %>%
  filter(abb != "AK") %>%
  filter(abb != "HI")

combined <-left_join(combined1, population %>% mutate(id = tolower(id)), by = "id")

combined <- combined %>%
  mutate(per_capita = total/`2018 Population`)

#graph

ggplot(data = combined) +
  geom_sf(aes(fill = per_capita))

ggplot(data = combined1)+
  geom_sf(aes(fill = total)) + 
  labs(title = "Map of USA, Number of Colleges by State")

#bin data
combined %>%
  mutate(capita_cut = cut_number(per_capita, 4))%>%
  ggplot() +
  geom_sf(aes(fill = capita_cut)) +
  labs(title = "Number of Universities", 
       subtitle = "Divided by State Population") +
  guides(fill=guide_legend(title="Number of Universities Per Person"))

combined1 %>%
  mutate(total_cut = cut_number(total, 4))%>%
  ggplot() +
  geom_sf(aes(fill = total_cut)) +
  labs(title = "Number of Universities in each State")


display.brewer.all(type = "div")

```


```{r}
#importing college data

col_shape <- st_read("/Users/AbigailBergman/Desktop/Grad School/Fall Quarter 2018/Computing/Homework/hw7/CollegesUniversities/CollegesUniversities.shp")

#get rid of alaska and hawaii
college_shape <- col_shape %>%
  filter(COUNTRY == "US") %>%
  filter(LSTATE != "HI") %>%
  filter(LSTATE != "AK")

ggplot(data = college_shape) +
  geom_sf()

st_as_sf(fifty_states, coords = c("long", "lat")) %>% 
  # convert sets of points to polygons
  group_by(id, piece) %>% 
  summarize(do_union = FALSE) %>%
  st_cast("POLYGON")%>%
  group_by(id) %>%
  summarize()

st_crs(sf_fifty) <- 4326

ggplot(data = combined1) +
  geom_sf() +
  geom_point(data = college_shape, aes(LON, LAT)) 

#map with total by color and points for enrollment
combined1 %>%
  mutate(total_cut = cut_number(total, 4))%>%
  ggplot() +
  geom_sf(aes(fill = total_cut)) +
  labs(title = "Number of Universities in each State") + 
  geom_point(data = college_shape, aes(x = LON, y = LAT, size = TOT_ENROLL), shape = 1, fill = "grey", alpha = .15)

#find out how to remove alaska and hawaii
#why isnt total enrollment changing the size

#blank map with colleges
ggplot(data = sf_fifty) +
  geom_sf() +
  labs(title = "Number of Universities in each State") + 
  geom_point(data = college_shape, aes(x = LON, y = LAT, size = TOT_ENROLL), alpha = .1, shape = 1)
```
For this assignment, I was interested in exploring the density of universities in different states. 